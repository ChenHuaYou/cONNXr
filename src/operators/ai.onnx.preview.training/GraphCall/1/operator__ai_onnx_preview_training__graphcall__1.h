//this file was generated by ../../../../../../scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX_PREVIEW_TRAINING__GRAPHCALL__1_H
# define OPERATOR_OPERATOR__AI_ONNX_PREVIEW_TRAINING__GRAPHCALL__1_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx.preview.training operator 'GraphCall' version 1
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * The GraphCall operator invokes a graph inside TrainingInfoProto's
 * algorithm field. The GraphCall inputs and outputs are bound to those of
 * invoked graph by position. If a graph input has an initializer, that input
 * is considered optional. All graph outputs are optional.
 * 
 * Below Python syntax is used for describing dictionary and list.
 * 
 * Assume that ModelProto's graph field has
 * - name: "MyInferenceGraph"
 * - input: ["X", "W", "Z"]
 * - initializer: [W]
 * - output: ["Y"]
 * 
 * as visualized below for inference.
 * 
 * ```
 * X -----.
 *        |
 *        v
 * W --> Conv --> H --> Gemm --> Y
 *                       ^
 *                       |
 *                       Z
 * ```
 * 
 * Assume that the training algorithm contains
 * 
 * - inputs: ["X_1", "Z_1", "C"]
 * - initializer: [T]
 * - outputs: ["W_new"]
 * 
 * with a dictionary
 * 
 * - update_binding: {"W": "W_new", "T": "T_new"}
 * 
 * Inside the training algorithm graph, one can invoke the inference
 * graph via adding a GraphCall node with
 * 
 * - inputs: ["X_1", "W", Z_1"]
 * - outputs: ["Y_1"]
 * - an attribute graph_name="MyInferenceGraph",
 * 
 * The initializers, "W" and "T" in this case, in update_binding
 * are considered globally-visible and mutable variables, which
 * can be used as inputs of operators in the training graph.
 * 
 * An example training algorithm graph may look like
 * 
 * ```
 * .-------- W (a global and mutable variable from
 * |         |  the inference graph)
 * |         |
 * |   .-----'-----------.
 * |   |                 |
 * |   |                 v
 * |   | .-- X_1 --> GraphCall(graph_name="MyInferenceGraph")
 * |   | |            |  |
 * |   | |            |  |
 * |   | |   Z_1 -----'  |
 * |   | |    |          V
 * |   | |    |         Y_1 ---> Loss ---> O
 * |   | |    |                    ^
 * |   | |    |                    |
 * |   | `--. |                    C
 * |   |    | |                    |
 * |   |    | |   .----------------'
 * |   |    | |   |
 * |   |    v v   v
 * |   `--> Gradient(xs=["W"], zs=["X_1", "Z_1", "C"], y="O")
 * |        |
 * |        v
 * |      dO_dW (gradient of W)      1 (a scalar one)
 * |        |                        |
 * |        V                        v
 * |       Div <--- T ------------> Add ---> T_new
 * |        |    (T is the number of training iterations.
 * |        |     T is also globally visible and mutable.)
 * |        v
 * `-----> Sub ----> W_new
 * ```
 * 
 * where Loss is a dummy node which computes the minimized objective function.
 * 
 * The variable "W" is an optional input in the called graph.
 * If the user omits it, the input list of GraphCall becomes ["X_1", "", "Z_1"].
 * In this case, from the view of computation graph, the Conv operator invoked by
 * GraphCall's may be still connected the global "W" variable and therefore the
 * structure of the computation graph is unchanged.
 * 
 * Constraint T:
 *   Allow inputs and outputs to be any kind of tensor.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Input T Inputs:
 *   Inputs fed to the invoked graph. The i-th input here goes to the i-th
 *   input of the invoked graph. To omit an optional input in this field, the
 *   user can drop it or use an empty string.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Output T Outputs:
 *   The outputs generated by the called graph. Its i-th value is bound to the
 *   i-th output of the called graph. Similar to the inputs, all outputs are
 *   optional.
 *   Allowed Types: tensor_bool, tensor_complex128, tensor_complex64,
 *                  tensor_double, tensor_float, tensor_float16, tensor_int16,
 *                  tensor_int32, tensor_int64, tensor_int8, tensor_string,
 *                  tensor_uint16, tensor_uint32, tensor_uint64, tensor_uint8
 * Attribute STRING graph_name :
 *   The invoked graph's name. The only allowed value is the name of the
 *   inference graph, which is stored in "ModelProto.graph.name" in the ONNX
 *   model format.
 *
 * @since version 1
 *
 * @see io/onnx/onnx/defs/training/defs.cc:325
 * @see 
 */

operator_status
prepare_operator__ai_onnx_preview_training__graphcall__1(
    node_context *ctx
);

extern operator_info info_operator__ai_onnx_preview_training__graphcall__1;

typedef struct {
    char* graph_name;

} context_operator__ai_onnx_preview_training__graphcall__1;

operator_executer
resolve_operator__ai_onnx_preview_training__graphcall__1(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_bool(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_complex128(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_complex64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_double(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_float(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_float16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_int16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_int32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_int64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_int8(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_string(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_uint16(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_uint32(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_uint64(
    node_context *ctx
);

operator_status
execute_operator__ai_onnx_preview_training__graphcall__1__T_tensor_uint8(
    node_context *ctx
);

# endif