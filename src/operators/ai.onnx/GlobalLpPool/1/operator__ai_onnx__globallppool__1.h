//this file was generated by ../../../../../../scripts/onnx_generator/OperatorHeader.py
# ifndef OPERATOR_OPERATOR__AI_ONNX__GLOBALLPPOOL__1_H
# define OPERATOR_OPERATOR__AI_ONNX__GLOBALLPPOOL__1_H

# include "operators/operator.h"
# include "operators/operator_stub.h"
# include "operators/operator_info.h"

/**
 * ai.onnx operator 'GlobalLpPool' version 1
 *
 * @param[in]  ctx  Operator context
 * @return          Status code
 *
 * GlobalLpPool consumes an input tensor X and applies lp pool pooling across the
 *  the values in the same channel. This is equivalent to LpPool with kernel size
 *  equal to the spatial dimension of input tensor.
 * 
 * Constraint T:
 *   Constrain input and output types to float tensors.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Input T X:
 *   Input data tensor from the previous operator; dimensions for image case
 *   are (N x C x H x W), where N is the batch size, C is the number of
 *   channels, and H and W are the height and the width of the data. For non
 *   image case, the dimension are in the form of (N x C x D1 x D2 ... Dn),
 *   where N is the batch size.
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Output T Y:
 *   Output data tensor from pooling across the input tensor. Dimensions will
 *   be N x C x 1 x 1
 *   Allowed Types: tensor_double, tensor_float, tensor_float16
 * Attribute FLOAT p (optional):
 *   p value of the Lp norm used to pool over the input data, default is 2.0.
*
* @since version 1
*
 * @see io/onnx/onnx/defs/nn/old.cc:1250
 * @see https://github.com/onnx/onnx/blob/master/docs/Operators.md#GlobalLpPool
*/

operator_status
prepare_operator__ai_onnx__globallppool__1(
    Onnx__NodeProto *ctx
);

extern operator_info info_operator__ai_onnx__globallppool__1;

typedef struct {
    float p;

} context_operator__ai_onnx__globallppool__1;

operator_status
execute_operator__ai_onnx__globallppool__1(
    Onnx__NodeProto *ctx
);

# endif