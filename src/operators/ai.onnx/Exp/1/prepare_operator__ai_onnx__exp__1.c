//this file was generated by ../../../../../../scripts/onnx_generator/OperatorTemplate.py
#include "operator__ai_onnx__exp__1.h"
#include "tracing.h"
#include "utils.h"

operator_status
prepare_operator__ai_onnx__exp__1(
    Onnx__NodeProto *ctx
)
{
    TRACE_ENTRY(1);

    TRACE_NODE(2, true, ctx->onnx_node);

    /* UNCOMMENT AS NEEDED */

    //Onnx__TensorProto *i_input = searchInputByIndex(ctx, 0);

    // TRACE_TENSOR(2, true, i_input);

    // Onnx__AttributeProto *a_consumed_inputs = searchAttributeNyName(ctx->onnx_node->n_attribute,ctx->onnx_node->attribute,"consumed_inputs");

    // TRACE_ATTRIBUTE(2, a_consumed_inputs, a_consumed_inputs);

    Onnx__TensorProto *o_output = searchOutputByIndex(ctx, 0);

    /* ALLOCATE AND INITIALIZE CONTEXT HERE IF NEEDED */

    // size_t default_n_consumed_inputs = ;
    // int64_t* default_consumed_inputs = ;

    // context_operator__ai_onnx__exp__1 *op_ctx = NULL;
    // op_ctx = malloc(sizeof(context_operator__ai_onnx__exp__1));
    // TRACE_FATAL(0 , !op_ctx, "could not allocate executer_context");

    // op_ctx->n_consumed_inputs = a_consumed_inputs?a_consumed_inputs->n_ints:default_n_consumed_inputs;
    // op_ctx->consumed_inputs = a_consumed_inputs?a_consumed_inputs->ints:ARRAYDUP(default_consumed_inputs,default_n_consumed_inputs);
    // TRACE_FATAL(0, !op_ctx->consumed_inputs, "malloc failed");

    // TRACE_ARRAY(2, true, op_ctx->consumed_inputs, , op_ctx->n_consumed_inputs, "%" PRId64);

    /* INITIALIZE OUTPUTS DATA_TYPE AND SHAPE HERE */


    /* MALLOC OUTPUT TENSORS HERE */

    mallocTensorData(o_output);

    // TRACE_TENSOR(2, true, o_output);

    /* CHOOSE EXECUTER AND CONTEXT HERE */
    /* YOU MAY USE THE GENERATED RESOLVER */

    ctx->executer = execute_operator__ai_onnx__exp__1;
    // ctx->executer_context = op_ctx;

    TRACE_EXIT(1);

    /* CHANGE RETURN CODE IF THIS PREPARER IS VALID */
    return OP_ENOSYS;
    // return OP_OK;
}